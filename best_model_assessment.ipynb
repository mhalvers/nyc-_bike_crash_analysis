{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate in detail the best-performing model found with the grid search cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the usual\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# my utilities\n",
    "from crash_utils.zip_code_and_borough_from_coords import zip_code_and_borough_from_coords\n",
    "from crash_utils.fix_vehicle_names import fix_vehicle_names\n",
    "from crash_utils.make_crash_features import make_crash_features\n",
    "from crash_utils.basic_cleaning import basic_cleaning\n",
    "from crash_utils.prepare_data_for_modelling import prepare_data_for_modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/Users/Mark/brainstation/capstone/nyc_bike_crash_analysis/data/\"\n",
    "df = pd.read_csv(data_path + \"Motor_Vehicle_Collisions_-_Crashes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in missing zip coded and boroughs using lat/lon\n",
    "df = zip_code_and_borough_from_coords(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## clean up the VEHICLE TYPE CODE columns\n",
    "df = fix_vehicle_names(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform some basic data munging operations (see `crash_utils/basic_cleaning.py` for details)\n",
    "df = basic_cleaning(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final prep (drops unncessary columns, feature engineering, count-vectorizer, OHE)\n",
    "df = prepare_data_for_modelling(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# now evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# machine learning stuff\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extract the features and targets from the big dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract target and features and then train-test-split\n",
    "\n",
    "X = df.iloc[:,1:]\n",
    "y = df.iloc[:,0]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fix the class imbalance with upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix the class imbalance with upsampling\n",
    "n_min = np.sum(y_train == 0)\n",
    "n_maj = np.sum(y_train == 1)\n",
    "minority_mask = y_train == 0\n",
    "\n",
    "X_upsampled, y_upsampled = resample(X_train.loc[minority_mask], \n",
    "                                    y_train.loc[minority_mask], \n",
    "                                    replace = True, \n",
    "                                    n_samples = n_maj)\n",
    "\n",
    "X_train_bal = np.vstack((X_train[y_train == 1], X_upsampled))\n",
    "y_train_bal = np.hstack((y_train[y_train == 1], y_upsampled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run what was found to be the best classifier\n",
    "\n",
    "run what was found to be the best classifier (file: 2020-12-10 00:30:04 GridCVresults.pkl)\n",
    "\n",
    "PCA(n_components=20), RandomForestClassifier(max_depth=40, n_estimators = 200, 'scaler': None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply pca transformation\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "my_pca = PCA(n_components=20).fit(X_train_bal)\n",
    "X_train_bal_pca = my_pca.transform(X_train_bal)\n",
    "X_test_pca = my_pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit random forest model to the upsampled, balanced, and PCA'ed training set\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(max_depth=40, n_estimators=200)\n",
    "rf.fit(X_train_bal_pca, y_train_bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the accuracy on the training and test sets\n",
    "print(f\"Accuracy on the training set: {round(100*rf.score(X_train_bal_pca, y_train_bal),2)}%\")\n",
    "print(f\"Accuracy on test set: {round(100*rf.score(X_test_pca, y_test),2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## accuracy, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict test and train\n",
    "y_pred_test = rf.predict(X_test_pca)\n",
    "y_pred_train= rf.predict(X_train_bal_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_test,normalize=\"all\")\n",
    "conf_df = 100*pd.DataFrame(data =  conf_matrix,\n",
    "                       index = [\"True non-injury\",\"True injury\"],\n",
    "                       columns = [\"Predicted non-injury\",\"Predicted injury\"]).round(2)\n",
    "\n",
    "conf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "plot_confusion_matrix(rf, X_test_pca, y_test, ax=ax,\n",
    "                      cmap=plt.cm.Blues, normalize=None,\n",
    "                      display_labels=[\"No injury\",\"Injury\"])\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"/Users/Mark/brainstation/capstone/nyc_bike_crash_analysis/figs/confusion_matrix.png\", facecolor=\"w\", edgecolor='none')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_df = pd.DataFrame(y_test.value_counts().sort_index())\n",
    "counts_df.rename(columns = {\"outcome\":\"number\"}, inplace=True)\n",
    "counts_df[\"outcome\"] = [\"no injury\",\"injury\"]\n",
    "counts_df.index.name = \"encoding\"\n",
    "counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"accuracy: {round(accuracy_score(y_test, y_pred_test),2)}\")\n",
    "print(f\"precision: {round(precision_score(y_test, y_pred_test),2)}\")\n",
    "print(f\"recall: {round(recall_score(y_test, y_pred_test),2)}\")\n",
    "print(f\"F1 score: {round(f1_score(y_test, y_pred_test),2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_initial = classification_report(y_test, y_pred_test)\n",
    "print(report_initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "plot_roc_curve(rf, X_test_pca, y_test, ax=ax)\n",
    "ax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "        label='chance')\n",
    "ax.legend(loc=\"lower right\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"/Users/Mark/brainstation/capstone/nyc_bike_crash_analysis/figs/roc_curve.png\", facecolor=\"w\", edgecolor='none')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic classifier to quantify the relative importance of the factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(C = 1e-6)\n",
    "lr.fit(X_train_scaled, y_train_bal)\n",
    "\n",
    "print(\"training set accuracy\",round(lr.score(X_train_scaled, y_train_bal),3))\n",
    "print(\"test set accuracy\",round(lr.score(X_test_scaled, y_test),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cs = 10**np.arange(-9.,5.,1.)\n",
    "test_score = []\n",
    "train_score = []\n",
    "\n",
    "for C in Cs:\n",
    "    lr = LogisticRegression(C = C).fit(X_train_scaled, y_train_bal)\n",
    "    train_score.append(lr.score(X_train_scaled, y_train_bal))\n",
    "    test_score.append(lr.score(X_test_scaled, y_test))\n",
    "    print(C,end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_ind = np.argmax(test_score)\n",
    "print(\"max test score of\", round(test_score[max_ind],3))\n",
    "print(\"max test score at C = \",Cs[max_ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the result\n",
    "plt.figure()\n",
    "plt.plot(Cs, train_score, label='training set', marker='o')\n",
    "plt.plot(Cs, test_score, label='test set', marker='o')\n",
    "plt.xscale(\"log\")\n",
    "plt.xlabel('C (inverse regularization strength)')\n",
    "plt.ylabel('accuracy score')\n",
    "plt.title(\"Logistic Regression Classification: impact of regularization\")\n",
    "plt.axvline(Cs[max_ind],color=\"k\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# break out the coefficient values and feature names for text columns\n",
    "coeffs = lr.coef_.reshape(-1)[253:]\n",
    "features = X.columns[253:]\n",
    "print(features.shape)\n",
    "print(coeffs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_df = pd.DataFrame({\"coeffs\":coeffs, \"word\":features})\n",
    "word_df.sort_values(by=\"coeffs\",ascending=False,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_df.head(20).plot.bar(x = \"word\", rot=90, figsize=(14,8), fontsize=16, legend=None);\n",
    "plt.xlabel(\"Coefficient value\",size=18);\n",
    "plt.ylabel(\"\");\n",
    "plt.title(\"Words that strongly predict injuries\",size = 20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
